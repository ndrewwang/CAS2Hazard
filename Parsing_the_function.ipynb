{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Thu Jun 23 17:17:45 2016\\n@author: Arnaud Devie\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun 23 17:17:45 2016\n",
    "@author: Arnaud Devie\n",
    "\"\"\"\n",
    "\n",
    "#%% Data mining from Sigma Aldrich website\n",
    "# Search URL by CAS number:\n",
    "# http://www.sigmaaldrich.com/catalog/search?interface=CAS%20No.&term=1314-62-1&N=0&lang=en&region=US&focus=product&mode=mode+matchall\n",
    "# On product page, Safety Information table, with H-statements, P-statements and PPE type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Libraries\n",
    "#==============================================================================\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "#==============================================================================\n",
    "# Functions\n",
    "#==============================================================================\n",
    "def deblank(text):\n",
    "    # Remove leading and trailing empty spaces\n",
    "    return text.rstrip().lstrip()\n",
    "\n",
    "def fixencoding(text):\n",
    "    # Make string compatible with cp437 characters set (Windows console)\n",
    "    return text.encode(encoding=\"cp437\", errors=\"ignore\").decode(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def deblankandcap(text):\n",
    "    # Remove leading and trailing empty spaces, capitalize\n",
    "    return text.rstrip().lstrip().capitalize()\n",
    "\n",
    "def striphtml(text):\n",
    "    # remove HTML tags from string (from: http://stackoverflow.com/a/3398894, John Howard)\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', text)\n",
    "\n",
    "def clean(text):\n",
    "    # Deblank, fix encoding and strip HTML tags at once\n",
    "    return striphtml(fixencoding(deblank(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'110-71-4', '646-06-0'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Input\n",
    "#==============================================================================\n",
    "# Looking for info about chemical identified by CAS number ...\n",
    "CASlist = list()\n",
    "textfile = open('CAS-list.txt','r')\n",
    "for line in textfile:\n",
    "    CASlist.append(deblank(line.replace('\\n','')))\n",
    "\n",
    "textfile.close()\n",
    "\n",
    "# Drop duplicates\n",
    "CASlist = set(CASlist)\n",
    "\n",
    "# Clean up\n",
    "if '' in CASlist:\n",
    "    CASlist.remove('')\n",
    "\n",
    "display(CASlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#==============================================================================\n",
    "# Search patterns\n",
    "#==============================================================================\n",
    "Ppattern = '(P[0-9]{3}[0-9P\\+]*)' # the letter P followed by 3 digits, including '+' combo\n",
    "#Hpattern = 'H[0-9]{3}' # the letter H followed by 3 digits\n",
    "Hpattern = '(H[0-9]{3}(?i)[ifd0-9H\\+]*)' # the letter H followed by 3 digits, including '+' combo, case insensitive fd\n",
    "\n",
    "# Parse H2P text file\n",
    "# alternate syntax : with open('') as file:\n",
    "textfile = open('H2P.txt', 'r')\n",
    "\n",
    "# Initialize dictionary\n",
    "H2P = dict()\n",
    "\n",
    "for line in textfile:\n",
    "    line = line.replace('\\n','').replace('+ ','+') #.replace(',','')\n",
    "    if re.match(Hpattern, line):\n",
    "        hcode = re.match(Hpattern, line).group()\n",
    "        H2P[hcode] = set(re.findall(Ppattern, line))\n",
    "\n",
    "# Close textfile\n",
    "textfile.close()\n",
    "\n",
    "# Parse P-statements text file\n",
    "textfile = open('P-statements.txt', 'r')\n",
    "\n",
    "# Initialize dictionary\n",
    "Pstatements = dict()\n",
    "\n",
    "for line in textfile:\n",
    "    line = line.replace('\\n','').replace(' + ','+')\n",
    "    if re.match(Ppattern, line):\n",
    "        pcode = deblank(re.match(Ppattern, line).group())\n",
    "        Pstatements[pcode] = deblank(line.split(pcode)[-1])\n",
    "\n",
    "# Close textfile\n",
    "textfile.close()\n",
    "\n",
    "# Parse H-statements text file\n",
    "textfile = open('H-statements.txt', 'r')\n",
    "\n",
    "# Initialize dictionary\n",
    "Hstatements = dict()\n",
    "\n",
    "for line in textfile:\n",
    "    line = line.replace('\\n','').replace(' + ','+')\n",
    "    if re.match(Hpattern, line):\n",
    "        hcode = deblank(re.match(Hpattern, line).group())\n",
    "        Hstatements[hcode] = deblank(line.split(hcode)[-1])\n",
    "\n",
    "# Close textfile\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Prevention, Response, Storage and Disposal P-statement from H-code\n",
    "#==============================================================================\n",
    "H2Prevention = dict()\n",
    "H2Response = dict()\n",
    "H2Storage = dict()\n",
    "H2Disposal = dict()\n",
    "\n",
    "for hcode in H2P:\n",
    "    alist = H2Prevention.get(hcode,[])\n",
    "    for pcode in H2P[hcode]:\n",
    "        statement = Pstatements[pcode]\n",
    "        if (pcode[1]=='2'): H2Prevention[hcode] = H2Prevention.get(hcode,[]); H2Prevention[hcode].append(statement)\n",
    "        if (pcode[1]=='3'): H2Response[hcode]   = H2Response.get(hcode,[]); H2Response[hcode].append(statement)\n",
    "        if (pcode[1]=='4'): H2Storage[hcode]    = H2Storage.get(hcode,[]); H2Storage[hcode].append(statement)\n",
    "        if (pcode[1]=='5'): H2Disposal[hcode]   = H2Disposal.get(hcode,[]); H2Disposal[hcode].append(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.sigmaaldrich.com/catalog/search?interface=CAS%20No.&term=110-71-4&N=0&lang=en&region=US&focus=product&mode=mode+matchall'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#==============================================================================\n",
    "# Data mining Sigma Aldrich website\n",
    "#==============================================================================\n",
    "\n",
    "# Start Chrome instance\n",
    "chromeOptions = webdriver.ChromeOptions()\n",
    "\n",
    "if \"SDS\" not in os.listdir():\n",
    "    os.mkdir(\"SDS\")\n",
    "\n",
    "prefs = {\"download.default_directory\" : os.path.join(os.getcwd(),\"SDS\"),\n",
    "         \"download.prompt_for_download\" : False,\n",
    "         \"download.directory_upgrade\" : True,\n",
    "         \"plugins.plugins_disabled\" : [\"Chrome PDF Viewer\"]}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "chromeOptions.add_argument(\"--disable-extensions\")\n",
    "\n",
    "# if 'win' in sys.platform: # Windows\n",
    "#     chromedriver = os.path.join(os.getcwd(),'chromedriver','win32','chromedriver.exe')\n",
    "# elif 'darwin' in sys.platform: # Mac OS\n",
    "#     chromedriver = os.path.join(os.getcwd(),'chromedriver','mac32','chromedriver')\n",
    "# elif 'linux' in sys.platform: # Linux\n",
    "#     if sys.maxsize > 2**32: # 64-bit\n",
    "#         chromedriver = os.path.join(os.getcwd(),'chromedriver','linux64','chromedriver')\n",
    "#     else: # 32-bit\n",
    "#         chromedriver = os.path.join(os.getcwd(),'chromedriver','linux32','chromedriver')\n",
    "\n",
    "chromedriver = os.path.join(os.getcwd(),'chromedriver','chromedriver')\n",
    "driver = webdriver.Chrome(executable_path=chromedriver, options=chromeOptions)\n",
    "# driver.set_window_position(-2000, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110-71-4\n",
      "No Synonyms listed for 110-71-4 - \n"
     ]
    }
   ],
   "source": [
    "chemicals=list()\n",
    "CASdict = dict()\n",
    "badCAS = list()\n",
    "\n",
    "CAS = '110-71-4'\n",
    "\n",
    "chemical = dict()\n",
    "URL = dict()\n",
    "Name = ''\n",
    "\n",
    "# Store CAS #\n",
    "chemical['CAS'] = CAS\n",
    "print(CAS)\n",
    "\n",
    "\n",
    "# Webscraping search page\n",
    "searchURL = r'http://www.sigmaaldrich.com/catalog/search?interface=CAS%20No.&term=[INSERT-HERE]&N=0&lang=en&region=US&focus=product&mode=mode+matchall'.replace('[INSERT-HERE]',CAS)\n",
    "# searchURL\n",
    "# searchURL = 'https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/'\n",
    "import requests\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'} \n",
    "# response = requests.get(url,headers=header)\n",
    "webpage = requests.get(searchURL,headers=header)\n",
    "webpage\n",
    "\n",
    "# webpage = urllib.request.urlopen(searchURL).read()\n",
    "\n",
    "soup = BeautifulSoup(webpage.content, \"html.parser\") # ===> Sigma is blocking BS4 scrape here\n",
    "# product = soup.find(\"li\", class_='productNumberValue')\n",
    "# print(product)\n",
    "\n",
    "# productSubURL = product.a.decode().split('\"')[1]\n",
    "# sds = soup.find(\"li\", class_='msdsValue')\n",
    "# pattern = '\\'(\\w*)\\'' # any string between ''\n",
    "# [country, language, productNumber, brand] = re.findall(pattern, sds.a.get('href'))\n",
    "# properties = soup.find(\"ul\", class_=\"nonSynonymProperties\")\n",
    "# formula = striphtml(properties.span.decode_contents())\n",
    "\n",
    "# Webscraping product page\n",
    "productURL = 'https://www.sigmaaldrich.com/GB/en/product/sial/259527'\n",
    "# productURL = 'http://www.sigmaaldrich.com[INSERT-HERE]'.replace('[INSERT-HERE]', productSubURL)\n",
    "webpage2 = requests.get(productURL,headers=header)\n",
    "# webpage2 = urllib.request.urlopen(productURL).read()\n",
    "soup2 = BeautifulSoup(webpage2.content, \"html.parser\")\n",
    "\n",
    "# # Store URLs\n",
    "# chemical['SearchURL'] = searchURL\n",
    "# chemical['ProductURL'] = productURL\n",
    "# chemical['ProductNumber'] = productNumber\n",
    "# chemical['Brand'] = brand\n",
    "# chemical['Formula'] = formula\n",
    "\n",
    "\n",
    "# Name (compatible with cp437 characters set)\n",
    "# Name = clean(soup2.find(\"h1\", itemprop=\"name\").decode_contents().split('\\n')[1])\n",
    "# chemical['Name'] = Name\n",
    "# CASdict[CAS] = Name\n",
    "# print(Name)\n",
    "\n",
    "# Synonyms\n",
    "try:\n",
    "    Synonyms = [clean(synonym) for synonym in soup2.find(\"p\", class_=\"synonym\").findNext(\"strong\").decode_contents().replace('\\t','').replace('\\n','').split(',')]\n",
    "    chemical['Synonyms'] = Synonyms\n",
    "except:\n",
    "    print('No Synonyms listed for %s - %s' % (CAS, Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-3\"><div><h3 class=\"MuiTypography-root jss293 MuiTypography-body2\">Hazard Statements</h3><div class=\"jss295\"><a class=\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiTypography-colorPrimary\" href=\"/GB/en/life-science/safety/hazard-and-precautionary-statements#hazard\">H225 - H315 - H332 - H360FD</a></div></div></div>\n"
     ]
    }
   ],
   "source": [
    "A = soup2.find_all(\"div\",class_=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-3\")[-9]\n",
    "A = str(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(H[0-9]{3}(?i)[ifd]*)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['H225', 'H315', 'H332', 'H360FD']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(soloHpattern)\n",
    "codes = re.findall(soloHpattern,A)\n",
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findNext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2b510cdf39f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoloHpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"safetyRight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Hazard statements\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ALL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findNext'"
     ]
    }
   ],
   "source": [
    "codes = re.findall(soloHpattern, soup2.find(\"div\", class_=\"safetyRight\", id=\"Hazard statements\").findNext(\"a\", class_=\"ALL\").decode_contents())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hazards listed for 110-71-4 - \n"
     ]
    }
   ],
   "source": [
    "soloHpattern = '(H[0-9]{3}(?i)[ifd]*)'\n",
    "try:\n",
    "    codes = re.findall(soloHpattern, soup2.find(\"div\", class_=\"safetyRight\", id=\"Hazard statements\").findNext(\"a\", class_=\"ALL\").decode_contents())\n",
    "    statements = [Hstatements[code] for code in codes]\n",
    "    Hazards = dict(zip(codes, statements))\n",
    "    chemical['Hazards'] =  Hazards\n",
    "except:\n",
    "    print('No Hazards listed for %s - %s' % (CAS, Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('Hazard Statements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110-71-4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize\n",
    "chemicals=list()\n",
    "CASdict = dict()\n",
    "badCAS = list()\n",
    "\n",
    "for CAS in CASlist:\n",
    "\n",
    "    chemical = dict()\n",
    "    URL = dict()\n",
    "    Name = ''\n",
    "\n",
    "    # Store CAS #\n",
    "    chemical['CAS'] = CAS\n",
    "    print(CAS)\n",
    "\n",
    "    try:\n",
    "        # Webscraping search page\n",
    "        searchURL = r'http://www.sigmaaldrich.com/catalog/search?interface=CAS%20No.&term=[INSERT-HERE]&N=0&lang=en&region=US&focus=product&mode=mode+matchall'.replace('[INSERT-HERE]',CAS)\n",
    "        webpage = urllib.request.urlopen(searchURL).read()\n",
    "        soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "        product = soup.find(\"li\", class_='productNumberValue')\n",
    "        productSubURL = product.a.decode().split('\"')[1]\n",
    "        sds = soup.find(\"li\", class_='msdsValue')\n",
    "        pattern = '\\'(\\w*)\\'' # any string between ''\n",
    "        [country, language, productNumber, brand] = re.findall(pattern, sds.a.get('href'))\n",
    "        properties = soup.find(\"ul\", class_=\"nonSynonymProperties\")\n",
    "        formula = striphtml(properties.span.decode_contents())\n",
    "\n",
    "        # Webscraping product page\n",
    "        productURL = 'http://www.sigmaaldrich.com[INSERT-HERE]'.replace('[INSERT-HERE]', productSubURL)\n",
    "        webpage2 = urllib.request.urlopen(productURL).read()\n",
    "        soup2 = BeautifulSoup(webpage2, \"html.parser\")\n",
    "\n",
    "        # Store URLs\n",
    "        chemical['SearchURL'] = searchURL\n",
    "        chemical['ProductURL'] = productURL\n",
    "        chemical['ProductNumber'] = productNumber\n",
    "        chemical['Brand'] = brand\n",
    "        chemical['Formula'] = formula\n",
    "\n",
    "\n",
    "        # Name (compatible with cp437 characters set)\n",
    "        Name = clean(soup2.find(\"h1\", itemprop=\"name\").decode_contents().split('\\n')[1])\n",
    "        chemical['Name'] = Name\n",
    "        CASdict[CAS] = Name\n",
    "        print(Name)\n",
    "\n",
    "        # Synonyms\n",
    "        try:\n",
    "            Synonyms = [clean(synonym) for synonym in soup2.find(\"p\", class_=\"synonym\").findNext(\"strong\").decode_contents().replace('\\t','').replace('\\n','').split(',')]\n",
    "            chemical['Synonyms'] = Synonyms\n",
    "        except:\n",
    "            print('No Synonyms listed for %s - %s' % (CAS, Name))\n",
    "\n",
    "        # List of H-statements\n",
    "        soloHpattern = '(H[0-9]{3}(?i)[ifd]*)'\n",
    "        try:\n",
    "            codes = re.findall(soloHpattern, soup2.find(\"div\", class_=\"safetyRight\", id=\"Hazard statements\").findNext(\"a\", class_=\"ALL\").decode_contents())\n",
    "            statements = [Hstatements[code] for code in codes]\n",
    "            Hazards = dict(zip(codes, statements))\n",
    "            chemical['Hazards'] =  Hazards\n",
    "        except:\n",
    "            print('No Hazards listed for %s - %s' % (CAS, Name))\n",
    "\n",
    "        # List of P-statements\n",
    "        soloPpattern = '(P[0-9]{3})'\n",
    "        try:\n",
    "            codes = re.findall(Ppattern, soup2.find(\"div\", class_=\"safetyRight\", id=\"Precautionary statements\").findNext(\"a\", class_=\"ALL\").decode_contents().replace(' ',''))\n",
    "            statements = [' '.join([Pstatements[solo] for solo in re.findall(soloPpattern,code)]) for code in codes]\n",
    "            Precautions = dict(zip(codes, statements))\n",
    "            chemical['Precautions'] =  Precautions\n",
    "        except:\n",
    "            print('No Precautions listed for %s - %s' % (CAS, Name))\n",
    "\n",
    "        # List of supplemental (non-GHS) H-statements\n",
    "        try:\n",
    "            suppstatements = soup2.find(\"div\", class_=\"safetyRight\", id=\"Supplemental Hazard Statements\").decode_contents().split(',')\n",
    "            chemical['Supp. Hazards'] =  [deblank(s) for s in set(suppstatements) if deblank(s) is not '']\n",
    "        except:\n",
    "            print('No supp. Hazards listed for %s - %s' % (CAS, Name))\n",
    "\n",
    "        # List of PPE\n",
    "        try:\n",
    "            PPElist = soup2.find(\"div\", class_=\"safetyRight\", id=\"Personal Protective Equipment\").findAll(\"a\", class_=\"ALL\")\n",
    "            PPE = [deblank(ppe.decode_contents())[0].upper() + deblank(ppe.decode_contents())[1:] for ppe in PPElist]\n",
    "            chemical['PPE'] = PPE\n",
    "        except:\n",
    "            print('No PPE listed for %s - %s' % (CAS, Name))\n",
    "\n",
    "        # Download SDS as PDF file\n",
    "        sdsName = Name + \" - SDS.pdf\"\n",
    "        sdsURL = os.path.join(\"SDS\", sdsName)\n",
    "        chemical['SDSfile'] = sdsURL\n",
    "\n",
    "        if sdsName not in os.listdir('SDS'):\n",
    "\n",
    "            driver.get(\"http://www.sigmaaldrich.com/MSDS/MSDS/DisplayMSDSPage.do?country=%s&language=en&productNumber=%s&brand=%s\" %(country, productNumber, brand));\n",
    "            print(\"Downloading SDS file\", end='')\n",
    "\n",
    "            timedout = False\n",
    "            timeout = time.time()\n",
    "            while (\"PrintMSDSAction.pdf\" not in os.listdir('SDS')) and not timedout:\n",
    "                print(\".\", end='')\n",
    "                timeout = time.time() - timeout\n",
    "                timedout = (timeout>30)\n",
    "                time.sleep(1)\n",
    "\n",
    "            if timedout:\n",
    "                print(\" Timed Out! Could not get the file\")\n",
    "            else:\n",
    "                print(\" Done.\")\n",
    "                os.rename(os.path.join(\"SDS\",\"PrintMSDSAction.pdf\"), sdsURL)\n",
    "\n",
    "        # Store chemical\n",
    "        chemicals.append(chemical)\n",
    "\n",
    "    except:\n",
    "        badCAS.append(CAS)\n",
    "        print('Could not process %s - %s' % (CAS, Name))\n",
    "        e = sys.exc_info()[0]\n",
    "\n",
    "# Close Chrome instance\n",
    "driver.quit()\n",
    "\n",
    "# Display\n",
    "print('Processed %d chemicals out of %d CAS numbers received' % (len(chemicals),len(CASlist)))\n",
    "\n",
    "if len(badCAS) > 0:\n",
    "    print('Unable to process the following CAS numbers:')\n",
    "    for cas in badCAS: print(cas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
